#!/usr/bin/env python
#
# file: $NEDC_NFC/class/python/nedc_ml_tools_data/nedc_ml_tools_data.py
#
# revision history:
# 20241014 (SM): initial version
#
#
# This class encapsulates data that is to be used for ML Tools.
#------------------------------------------------------------------------------

# import required system modules
#
import os
import numpy as np
import pandas as pd
import copy
from collections import defaultdict

# import required NEDC modules
#
import nedc_debug_tools as ndt

# declare global debug and verbosity objects so we can use them
# in both functions and classes
#
dbgl_g = ndt.Dbgl()
vrbl_g = ndt.Vrbl()

#------------------------------------------------------------------------------
#
# global variables are listed here
#
#------------------------------------------------------------------------------

# set the filename using basename
#
__FILE__ = os.path.basename(__file__)

# define names of distributions so they can be generated by the class
#
GAUSSIAN = "gaussian"
TORODIAL = "toroidal"
YIN_YANG = "yin_yang"

#------------------------------------------------------------------------------
#
# classes are listed here
#
#------------------------------------------------------------------------------

class MLToolsData:
    """
    Class: MLToolsData

    arguments:
     none

    description:
     This is a class that encapsulates data that can be used with ML Tools.
    """

    def __init__(self, dir_path = "", lndx = 0, nfeats = -1):
        """
        method: constructor

        arguments:
         dir_path: directory path to the file ("")
         lndx: the label index (0)
         nfeats: number of features (-1)

        return:
         none

        description:
         none

        note:
         for nfeats, -1 means that we choose all of the features.
        """
        self.dir_path = dir_path
        self.lndx = lndx
        self.nfeats = nfeats

        self.data = []
        self.labels = []
        self.num_of_classes = 0
        self.mapping_label = {}

        if (dir_path != ""):
            self.load()

    def __repr__(self) -> str:
        return (f"MLToolData({self.dir_path}, label index = {self.lndx}, "
                f"# of features = {self.nfeats if self.nfeats != -1 else 'all'})")

    @classmethod
    def generate_data(cls, dist_name:str, params):
        '''
        function: generate_data

        arguments:
         dist_name: name of the distribution to generate data from
                    ('gaussian', 'toroidal', 'yin_yang')
         params: the parameters for the distribution. Should be a list of
                 dictionaries if guassian. Should be a dictionary if toroidal
                 or yin-yang.

        return:
         a MLToolsData object populated with the data from the distribution
        
        description:
         generate a MLToolsData object from a sp
        '''

        # generate the data for the distribution
        #
        if dist_name == GAUSSIAN: 
            if not isinstance(params, list):
                raise ValueError(
                    "Gaussian parameters must be a list of dictionaries.")
            else:
                X, y = generate_gaussian(params)

        elif dist_name == TORODIAL: 
            if not isinstance(params, dict):
                raise ValueError("Toroidal parameters must be a dictionary.")
            else:
                X, y = generate_toroidal(*params)

        elif dist_name == YIN_YANG:
            if not isinstance(params, dict):
                raise ValueError("Yin-Yang parameters must be a dictionary.")
            else:
                X, y = generate_yin_yang(*params)


        # take the data and labels and create a new MLToolsData object
        # exit gracefully
        #
        return cls.from_data(X, y)
    #
    # end of method

    @classmethod
    def from_data(cls, X:np.ndarray, y:list):
        """
        function: from_imld

        argument:
         X (np.ndarray): the data to be used. can be a N-dimensional array
         y (list)      : a 1-D list of labels for the data. should be the same
                         length as the number of rows in X.

        return:
         a MLToolData object

        description:
         this function is a classmethod that creates a new ML Tools Data object
         from a numpy array and a list of labels. This is useful for creating
         a class object from data that is not in a file.
        """
        self = cls.__new__(cls)
        self.dir_path = ""
        self.lndx = 0
        self.nfeats = -1
        self.num_of_classes = len(set(y))

        # save the data and labels
        #
        self.labels = np.asarray(y)
        self.data = np.asarray(X)

        # create the mapping label
        #
        self.mapping_label = {i: label for i, label in enumerate(set(y))}

        # convert the labels to numbers
        #
        self.labels = self.map_label()

        # save the mapped labels back into ints
        #
        self.labels = np.array(self.labels, dtype = int)

        # return the MLToolsData object
        #
        return self
    #
    # end of method

    @staticmethod
    def is_excel(fname):
        """
        function: is_excel

        arguments:
        fname: filename of the data

        return:
        a boolean value indicating status

        description:
        this function checks if file is an excel spreadsheet.
        """

        # use Pandas to open and parse the file. if this errors,
        # we assume it is a csv file.
        #
        try:
            pd.read_excel(fname)
        except ValueError:
            return False

        # exit gracefully
        #
        return True

    def map_label(self, labels:np.array=None):# -> type[list[_T]] | ndarray | NDArray:

        if labels is None:
            labels = np.array(self.labels)
            unique_labels = np.unique(labels)

        else:
            labels = np.array(labels)
            unique_labels = np.unique(labels)

        for i in range(len(unique_labels)):
            for j in range(len(labels)):
                if labels[j] == unique_labels[i]:
                    labels[j]=i

        return labels

    def load(self):
        """
        function: load_data

        arguments:
        None

        return:
        a list of numpy arrays or None if it fails

        description:
        this function reads data from either an excel sheet or csv file
        and converts it to a dictionary representing the labels and the data.

        Ex: data: {
            "labels": numpy.ndarray[0, 0, 0, 1, 1, 1, 1],
            "data"  : [np.ndarray[01,02,03],
                    [04,05,06],
                    [07,08,09],
                    [60,61,62],
                    [70,71,72],
                    [80,81,82],
                    [90,91,92]]
        }

        The example data above has 2 classes and 3 features.The labels ordering
        and data ordering are the same. The first three vectors are in class "0" and
        the last four are in class "1".

        for nfeats, it will use all the feature from the start to the specified value
        Not counting the label column.

        Ex: if nfeats = 3, then we assume column [0,1,2].

        Ex: If we have [0,1,2,3,4,5] and lndx = 1, nFeatures = 3 then the column
            features would be [0,2,3] since we exclude the column label.

        if the data fails to be loaded, an error is generated and None is returned.
        """

        # display an informational message
        #
        if dbgl_g == ndt.FULL:
            print("%s (line: %s) %s: reading data" %
                (__FILE__, ndt.__LINE__, ndt.__NAME__))

        try:
            if self.is_excel(self.dir_path):
                df = pd.read_excel(self.dir_path, header = None)
            else:
                df = pd.read_csv(self.dir_path, header = None, engine = "c", comment = "#")
        except Exception:
            raise("Error: %s (line: %s) %s: %s (%s)" %
                (__FILE__, ndt.__LINE__, ndt.__NAME__,
                "unknown file or data format", self.dir_path))

        if self.lndx >= df.shape[1]:
            print("Error: %s (line: %s) %s: %s" %
                (__FILE__, ndt.__LINE__, ndt.__NAME__,
                "Label index out of range"))
            return None

        # pop the label column
        #
        label_column = df.pop(self.lndx)

        # clear label map if there was one already
        #
        if not self.mapping_label:
            self.mapping_label.clear()

        # create a label map for readable label to an index.
        #   Note: Since we are sorting, the mapping will not always be in order if
        #         string because sorting uses string comparison
        #
        for ind, val in enumerate(sorted(label_column.unique())):

            if isinstance(val, str):
                self.mapping_label[ind] = val

            # assume any label that is not a string to be a integer
            #
            else:
                self.mapping_label[ind] = int(val)

        if self.nfeats >= df.shape[1] or self.nfeats < -1:
            self.nfeats = -1

        # if the number of feature is specified then we would need to reshape the
        # data frame
        #
        if self.nfeats != -1:
            df = df.iloc[:, : self.nfeats]

        # append the label column at the beginning of the dataframe
        # and rename its column
        #
        df = pd.concat([label_column, df], axis = 1)
        df.columns = list(range(df.shape[1]))

        # set the index of the table using the label column
        #
        df.set_index(df.keys()[0], inplace = True)

        self.data = df.values
        self.labels = df.index.to_numpy()
        self.num_of_classes = len(set(self.labels))


    def sort(self, inplace = False):
        """
        function: sort

        arguments:
         inplace: flag to sort the data inplace (False)

        return:
         If inplace = True -> returns None
         If inplace = False -> returns the sorted data

        description:
        this function sorts the given data model.
        """

        # samples and labels
        #
        samples = self.data
        labels = np.array(self.labels)

        # np.unique() returns a set of unique values that
        # is in order
        #
        uniq_labels = np.unique(labels)

        # empty list to save sorted data snd labels
        #
        sorted_data = []
        sorted_labels = []

        # loop through the unique labels
        #
        for element in uniq_labels:

            # empty list to save class labels and class data
            #
            class_data = []
            class_labels = []

            # loop through the len labels and compare labels with unique label
            #
            for i in range(len(labels)):
                if labels[i] == element:
                    class_data.append(samples[i])
                    class_labels.append(labels[i])

            sorted_data.extend(class_data)
            sorted_labels.extend(class_labels)

        sorted_data = np.array(sorted_data)
        sorted_labels = np.array(sorted_labels)

        if inplace:
            self.data = sorted_data
            self.labels = sorted_labels

            return None
        else:

            MLToolDataNew = copy.deepcopy(self)
            MLToolDataNew.data = sorted_data
            MLToolDataNew.labels = sorted_labels

            return MLToolDataNew

    def write(self, oname, label):
        """
        function: write

        argument:
         oname: the output file name
         label: the label to write

        return:
        boolean indicating the status

        description:
        this function writes the data with new label to a file
        """

        d = pd.DataFrame(self.data)

        #  add the label to the first column of the file
        #
        try:
            d.insert(0, column = "labels", value = label)
        except ValueError:
            print("Error: %s (line: %s) %s: %s" %
                (__FILE__, ndt.__LINE__, ndt.__NAME__,
                "Labels column already existed within the data"))
            return False

        if self.is_excel(self.dir_path):
            d.to_excel(oname)
        else:
            d.to_csv(oname, index = False, header = False)

        return True

    def group_by_class(self):
        """
        function: group_by_class

        argument:
         none

        return:
         group data

        description:
        this function group the data by the label
        """
        group_data = defaultdict(list)

        for label, data in zip(self.labels, self.data):
            group_data[label].append(data)

        return group_data

#
# end of dataclass
    
def generate_gaussian(params:list) -> tuple:
    '''
    function: generate_gaussian

    args:
     params (list): a list containing a dictionary of parameters for each
                    gaussian distribution to make.
                     params = [
                        {
                        'npts' (int): the number of points for the distribution
                        'mean' (1D list): the mean values for the distribution.
                                          should have the same length as the 
                                          number of features. 
                                          (e.g. [1, 2, 3] for 3 features)
                        'cov' (2D list): the covariance matrix for the 
                                         distribution. should be a square 
                                         matrix with the same dimensions as 
                                         the number of features.
                                         (e.g. [[0.1, 0.01, 0.02],
                                                [0.01, 0.1, 0.03],
                                                [0.02, 0.03, 0.1]] 
                                         for 3 features)
                        },
                        ...
                     ] 

    return:
     X (np.ndarray): a n-D array containing all of the data points 
                              generated. should contain the data for both 
                              classes.
     y (list): a 1-D list containing the labels for each sample in X   

     description:
      generate a gaussian distribution for a given number of labels. Works for 
      N-dimensionality. The number of features is determined by the length of 
      the mean and covariance matrix.
    '''

    # make sure parameters are provided
    #
    if len(params) == 0:
        raise ValueError("No parameters provided for gaussian distribution.")

    # iterate through the parameters for each gaussian distribution
    # and generate the data and labels for each distribution
    #
    for i, param in enumerate(params):

        # get parameters
        #
        try:
            npts, mean, cov = param['npts'], param['mean'], param['cov']
        except KeyError as e:
            missing_param = e.args[0]
            raise KeyError(
                f"Missing parameter '{missing_param}' for distribution {i}.")

        # check if the mean and covariance matrix are valid
        #
        if len(mean) != len(cov) or len(cov) != len(cov[0]):
            raise ValueError(
                "Mean and covariance matrix dimensions do not match.")
        
        # gaussian distribution for each class
        #
        data = np.random.multivariate_normal(mean, cov, npts)
        labels = [i] * npts

        # if this is the first iteration, set the class data and labels
        # to the data and labels generated in this iteration
        #
        if i == 0:
            X = data
            y = labels

        # if this is not the first iteration, append the data and labels
        # to the class data and labels
        #
        else:

            # check if the dimensions of the previous class data and the
            # current data match. if not, raise an error
            #
            if X.shape[1] != data.shape[1]:
                raise ValueError("Data dimensions do not match.")
            
            # if the dimensions match, append the data and labels to the
            # class data and labels
            #
            else:
                X = np.vstack((X, data))
                y += labels

    # exit gracefully
    #
    return X, y
#
# end of method

def generate_toroidal(mean:list,
                      cov:list,
                      npts_mass:int,
                      npts_ring:int,
                      inner_rad:float,
                      outer_rad:float) -> tuple:
    '''
    function generate_toroidal

    args:
     mean (1D list)   : the mean values for the distribution. should have the 
                        same length as the number of features. 
                        (e.g. [1, 2, 3] for 3 features)
     cov  (2D list)   : the covariance matrix for the inner gaussian mass
     npts_mass (int)  : the number of points to generate for the inner mass
     npts_ring (int)  : the number of points to generate for the ring
     inner_rad (float): the inner radius of the ring
     outer_rad (float): the outer radius of the ring

    return:
     X (np.ndarray): a n-D array containing all of the data points 
                              generated. should contain the data for both 
                              classes.
     y (list): a 1-D list containing the labels for each sample in X  

    description:
     generate a torodial distribution. This includes an inner gaussian mass
     and a hollow ring outside of it. This will only have two labels, but works
     with N-dimensionality.
    '''

    # error check for bad parameters
    #
    if not (outer_rad > inner_rad):
        raise ValueError("Outer radius must be greater than inner radius")
    if (inner_rad < 0) or (outer_rad < 0):
        raise ValueError("Radius values cannot be less than 0")

    # generate inner gaussian mass (class 0)
    #
    X, y = generate_gaussian([{'npts': npts_mass, 'mean': mean, 'cov': cov}])

    # get the number of dimensions
    #
    dims = len(mean)

    # generate random points on an N-dimensional unit sphere
    #
    random_vectors = np.random.normal(size=(npts_ring, dims))
    unit_vectors = random_vectors / np.linalg.norm(random_vectors, axis=1, keepdims=True)

    # scale vectors to lie within the toroidal ring (between inner_rad and outer_rad)
    # create the toroidal ring (class 1)
    #
    ring_radii = np.random.uniform(inner_rad, outer_rad, npts_ring).reshape(-1, 1)
    class_1_data = mean + unit_vectors * ring_radii

    # concatenate data w labels
    #
    X = np.vstack((X, class_1_data))
    y += ([1] * npts_ring)
    
    # exit gracefully
    #
    return X, y
#
# end of method

def generate_yin_yang(means:list,
                      radius:float,
                      npts_yin: int,
                      npts_yang: int,
                      overlap: float) -> tuple:
    '''
    function: generate_yin_yang

    args:
     means (1D list): the mean values for each feature. Should be of length 2 
                      (2D) or 3 (3D). For example, [0, 0] for 2D or 
                      [0, 0, 0] for 3D.
     radius (float) : the radius of the yin-yang circle
     npts_yin (int) : the number of points in the yin class (class 0)
     npts_yang (int): the number of points in the yang class (class 1)
     overlap (float): the amount of overlap between the yin and yang classes

    return:
     X (np.ndarray): a n-D array containing all of the data points 
                              generated. should contain the data for both 
                              classes.
     y (list): a 1-D list containing the labels for each sample in X 

    description:
     generate a yin-yang distribution. The yin class is defined in one half of
     the circle (or extruded sphere) and the yang class in the other half. 
     when working in 3D, the pattern is extruded along the z-axis (with z 
     sampled from a similar normal distribution) while keeping the yin-yang 
     decision based on the x and y coordinates.
    '''

    # determine the dimensionality from the length of means.
    #
    ndim = len(means)
    if ndim not in [2, 3]:
        raise ValueError("Please provide means for 2D or 3D data.")
    
    # Use provided means for the x and y (and z if available).
    if ndim == 2:
        xmean, ymean = means
    else:  # ndim == 3
        xmean, ymean, zmean = means

    # boundary, mean, and standard deviation of plot
    #
    stddev_center = 1.5 * (radius) / 2

    # calculate radii for yin-yang regions
    #
    radius1 = radius / 2
    radius2 = radius / 4

    # create empty lists for storing points
    #
    yin = []
    yang = []

    # counters to track generated points for each class
    #
    n_yin_counter = 0
    n_yang_counter = 0

    # Generate points for yin and yang
    #
    while n_yin_counter < npts_yin or n_yang_counter < npts_yang:

        # generate x and y coordinates
        #
        xpt = np.random.normal(xmean, stddev_center)
        ypt = np.random.normal(ymean, stddev_center)

        # generate z coordinate if 3D
        #
        if ndim == 3:
            zpt = np.random.normal(zmean, stddev_center)

        # calculate distances for each generated point
        #
        distance1 = np.sqrt(xpt ** 2 + ypt ** 2)
        distance2 = np.sqrt(xpt ** 2 + (ypt + radius2) ** 2)
        distance3 = np.sqrt(xpt ** 2 + (ypt - radius2) ** 2)

        # Determine point class based on position and distances
        #
        if distance1 <= radius1:
            if -radius1 <= xpt <= 0:
                if ((distance1 <= radius1 or distance2 <= radius2) and distance3 > radius2):

                    if n_yin_counter < npts_yin:
                        if ndim == 2:
                            yin.append([xpt, ypt])
                        else:
                            yin.append([xpt, ypt, zpt])
                        n_yin_counter += 1

                elif n_yang_counter < npts_yang:
                    if ndim == 2:
                        yang.append([xpt, ypt])
                    else:
                        yang.append([xpt, ypt, zpt])
                    n_yang_counter += 1

            elif 0 < xpt <= radius1:
                if ((distance1 <= radius1 or distance3 <= radius2) and distance2 > radius2):

                    if n_yang_counter < npts_yang:
                        if ndim == 2:
                            yang.append([xpt, ypt])
                        else:
                            yang.append([xpt, ypt, zpt])
                        n_yang_counter += 1

                elif n_yin_counter < npts_yin:
                    if ndim == 2:
                        yin.append([xpt, ypt])
                    else:
                        yin.append([xpt, ypt, zpt])
                    n_yin_counter += 1

    # translate yin and yang points along the y-axis to adjust overlap.
    # in 3D, we leave the z coordinate unchanged.
    #
    if ndim == 2:
        yin = np.array(yin) + np.array([0, overlap * radius2])
        yang = np.array(yang) - np.array([0, overlap * radius2])
    else:
        yin = np.array(yin) + np.array([0, overlap * radius2, 0])
        yang = np.array(yang) - np.array([0, overlap * radius2, 0])

    # return generated data as a dictionary
    # combine the yin and yang classes and create the labels
    #
    X = np.concatenate((yin, yang), axis=0)
    y = [0] * npts_yin + [1] * npts_yang

    # exit gracefully
    #
    return X, y
#
# end of function 

#
# end of file