#!/usr/bin/env python
#
# file: $NEDC_NFC/class/python/nedc_ml_tools_data/nedc_ml_tools_data.py
#
# revision history:
# 20241014 (SM): initial version
#
#
# This class encapsulates data that is to be used for ML Tools.
#------------------------------------------------------------------------------

# import required system modules
#
import os
import numpy as np
import pandas as pd
import copy
from collections import defaultdict

# import required NEDC modules
#
import nedc_debug_tools as ndt

# declare global debug and verbosity objects so we can use them
# in both functions and classes
#
dbgl_g = ndt.Dbgl()
vrbl_g = ndt.Vrbl()

#------------------------------------------------------------------------------
#
# global variables are listed here
#
#------------------------------------------------------------------------------

# set the filename using basename
#
__FILE__ = os.path.basename(__file__)

#------------------------------------------------------------------------------
#
# classes are listed here
#
#------------------------------------------------------------------------------

class MLToolsData:
    """
    Class: MLToolsData

    arguments:
     none

    description:
     This is a class that encapsulates data that can be used with ML Tools.
    """

    def __init__(self, dir_path = "", lndx = 0, nfeats = -1):
        """
        method: constructor

        arguments:
         dir_path: directory path to the file ("")
         lndx: the label index (0)
         nfeats: number of features (-1)

        return:
         none

        description:
         none

        note:
         for nfeats, -1 means that we choose all of the features.
        """
        self.dir_path = dir_path
        self.lndx = lndx
        self.nfeats = nfeats

        self.data = []
        self.labels = []
        self.num_of_classes = 0
        self.mapping_label = {}

        self.load()

    def __repr__(self) -> str:
        return (f"MLToolData({self.dir_path}, label index = {self.lndx}, "
                f"# of features = {self.nfeats if self.nfeats != -1 else 'all'})")

    # TODO: create wrapper function to generate data from a distribution and create
    #       a MLToolData object with it.
    @classmethod
    def generate_data(cls, dist_name:str):
        return

    @classmethod
    def from_imld(cls, imld_data):
        """
        function: from_imld

        argument:
         imld_data: data that is generated by IMLD

        return:
         a MLToolData object

        description:
         this function is a classmethod that creates a new MLToolData object
         from IMLD's data structure
        """
        self = cls.__new__(cls)
        self.dir_path = ""
        self.lndx = 0
        self.nfeats = -1
        self.num_of_classes = len(imld_data)

        labels = []
        data = []
        mapping_label = {}

        # converting the data into our new format
        #
        for i, lists in enumerate(imld_data):
            mapping_label[i] = i
            labels.extend([i] * len(lists))
            for item in lists:
                data.append(item)

        labels = np.asarray(labels)
        data = np.asarray(data)

        self.labels = labels
        self.data = data
        self.mapping_label = mapping_label

        return self

    @staticmethod
    def is_excel(fname):
        """
        function: is_excel

        arguments:
        fname: filename of the data

        return:
        a boolean value indicating status

        description:
        this function checks if file is an excel spreadsheet.
        """

        # use Pandas to open and parse the file. if this errors,
        # we assume it is a csv file.
        #
        try:
            pd.read_excel(fname)
        except ValueError:
            return False

        # exit gracefully
        #
        return True

    def map_label(self):# -> type[list[_T]] | ndarray | NDArray:

        labels = np.array(self.labels)
        unique_labels = np.unique(labels)

        labels = self.labels

        for i in range(len(unique_labels)):
            for j in range(len(labels)):
                if labels[j] == unique_labels[i]:
                    labels[j]=i

        return labels

    def load(self):
        """
        function: load_data

        arguments:
        None

        return:
        a list of numpy arrays or None if it fails

        description:
        this function reads data from either an excel sheet or csv file
        and converts it to a dictionary representing the labels and the data.

        Ex: data: {
            "labels": numpy.ndarray[0, 0, 0, 1, 1, 1, 1],
            "data"  : [np.ndarray[01,02,03],
                    [04,05,06],
                    [07,08,09],
                    [60,61,62],
                    [70,71,72],
                    [80,81,82],
                    [90,91,92]]
        }

        The example data above has 2 classes and 3 features.The labels ordering
        and data ordering are the same. The first three vectors are in class "0" and
        the last four are in class "1".

        for nfeats, it will use all the feature from the start to the specified value
        Not counting the label column.

        Ex: if nfeats = 3, then we assume column [0,1,2].

        Ex: If we have [0,1,2,3,4,5] and lndx = 1, nFeatures = 3 then the column
            features would be [0,2,3] since we exclude the column label.

        if the data fails to be loaded, an error is generated and None is returned.
        """

        # display an informational message
        #
        if dbgl_g == ndt.FULL:
            print("%s (line: %s) %s: reading data" %
                (__FILE__, ndt.__LINE__, ndt.__NAME__))

        try:
            if self.is_excel(self.dir_path):
                df = pd.read_excel(self.dir_path, header = None)
            else:
                df = pd.read_csv(self.dir_path, header = None, engine = "c", comment = "#")
        except Exception:
            raise("Error: %s (line: %s) %s: %s (%s)" %
                (__FILE__, ndt.__LINE__, ndt.__NAME__,
                "unknown file or data format", self.dir_path))

        if self.lndx >= df.shape[1]:
            print("Error: %s (line: %s) %s: %s" %
                (__FILE__, ndt.__LINE__, ndt.__NAME__,
                "Label index out of range"))
            return None

        # pop the label column
        #
        label_column = df.pop(self.lndx)

        # clear label map if there was one already
        #
        if not self.mapping_label:
            self.mapping_label.clear()

        # create a label map for readable label to an index.
        #   Note: Since we are sorting, the mapping will not always be in order if
        #         string because sorting uses string comparison
        #
        for ind, val in enumerate(sorted(label_column.unique())):

            if isinstance(val, str):
                self.mapping_label[ind] = val

            # assume any label that is not a string to be a integer
            #
            else:
                self.mapping_label[ind] = int(val)

        if self.nfeats >= df.shape[1] or self.nfeats < -1:
            self.nfeats = -1

        # if the number of feature is specified then we would need to reshape the
        # data frame
        #
        if self.nfeats != -1:
            df = df.iloc[:, : self.nfeats]

        # append the label column at the beginning of the dataframe
        # and rename its column
        #
        df = pd.concat([label_column, df], axis = 1)
        df.columns = list(range(df.shape[1]))

        # set the index of the table using the label column
        #
        df.set_index(df.keys()[0], inplace = True)

        self.data = df.values
        self.labels = df.index.to_numpy()
        self.num_of_classes = len(set(self.labels))


    def sort(self, inplace = False):
        """
        function: sort

        arguments:
         inplace: flag to sort the data inplace (False)

        return:
         If inplace = True -> returns None
         If inplace = False -> returns the sorted data

        description:
        this function sorts the given data model.
        """

        # samples and labels
        #
        samples = self.data
        labels = np.array(self.labels)

        # np.unique() returns a set of unique values that
        # is in order
        #
        uniq_labels = np.unique(labels)

        # empty list to save sorted data snd labels
        #
        sorted_data = []
        sorted_labels = []

        # loop through the unique labels
        #
        for element in uniq_labels:

            # empty list to save class labels and class data
            #
            class_data = []
            class_labels = []

            # loop through the len labels and compare labels with unique label
            #
            for i in range(len(labels)):
                if labels[i] == element:
                    class_data.append(samples[i])
                    class_labels.append(labels[i])

            sorted_data.extend(class_data)
            sorted_labels.extend(class_labels)

        sorted_data = np.array(sorted_data)
        sorted_labels = np.array(sorted_labels)

        if inplace:
            self.data = sorted_data
            self.labels = sorted_labels

            return None
        else:

            MLToolDataNew = copy.deepcopy(self)
            MLToolDataNew.data = sorted_data
            MLToolDataNew.labels = sorted_labels

            return MLToolDataNew

    def write(self, oname, label):
        """
        function: write

        argument:
         oname: the output file name
         label: the label to write

        return:
        boolean indicating the status

        description:
        this function writes the data with new label to a file
        """

        d = pd.DataFrame(self.data)

        #  add the label to the first column of the file
        #
        try:
            d.insert(0, column = "labels", value = label)
        except ValueError:
            print("Error: %s (line: %s) %s: %s" %
                (__FILE__, ndt.__LINE__, ndt.__NAME__,
                "Labels column already existed within the data"))
            return False

        if self.is_excel(self.dir_path):
            d.to_excel(oname)
        else:
            d.to_csv(oname, index = False, header = False)

        return True

    def group_by_class(self):
        """
        function: group_by_class

        argument:
         none

        return:
         group data

        description:
        this function group the data by the label
        """
        group_data = defaultdict(list)

        for label, data in zip(self.labels, self.data):
            group_data[label].append(data)

        return group_data

#
# end of dataclass
    
def generate_yin_yang(params:dict) -> tuple:
    '''
    function generate_yin_yang

    args:
    params (dict): a dictionary containing the parameters for the distribution.
                    params = {
                                'npts_yin' (int) : the number of points to generate for the yin
                                'npts_yang' (int): the number of points to generate for the yang
                                'ovlp' (float)   : the overlap between the yin and yang
                                'x_mean' (float)  : the xmean of the yin yang
                                'y_mean' (float)  : the ymean of the yin yang
                                'x_min' (float)  : the minimum x value for the data
                                'x_max' (float)  : the maximum x value for the data
                                'y_min' (float)  : the minimum y value for the data
                                'y_max' (float)  : the maximum y value for the data
                            }

    return:
        MLToolsData: an instance of ML Tools Data containing the distribution

    description:
    generate two masses that create a yin yang, each of different labels.
    '''

    np.random.seed(1)

    # the boundary, mean and std of the plot
    #
    stddev_center = 1.5 * (params['x_max'] - params['x_min']) / 2

    # creating empty lists to save coordinates of points
    #
    yin = []
    yang = []

    # calculate the radius of each class on the plot
    #
    radius1 = 1.5 * ((params['x_max'] - params['x_min']) / 4)
    radius2 = 0.75 * ((params['x_max'] - params['x_min']) / 4)

    # define the number of samples in each class by checking the user-specified
    # values and setting defaults if there are none
    #
    n_yin = params['npts_yin']
    n_yang = params['npts_yang']

    print(params['xmean'])
    print(params['y_mean'])
    print(radius1)
    print(radius2)

    # producing some random numbers based on a Gaussian distirbution and then
    # calculating the points distance to each class, choosing the closest set.
    # the loop will exit when both classes has been generated
    #
    n_yin_counter = 0
    n_yang_counter = 0
    while ((n_yin_counter < n_yin) or (n_yang_counter < n_yang)):

        # generate points with Gaussian distribution
        #
        xpt = np.random.normal(params['x_mean'], stddev_center, 1)[0]
        ypt = np.random.normal(params['y_mean'], stddev_center, 1)[0]

        # calculate radius for each generated point
        #
        distance1 = np.sqrt(xpt ** 2 + ypt ** 2)
        distance2 = np.sqrt(xpt ** 2 + (ypt + radius2) ** 2)
        distance3 = np.sqrt(xpt ** 2 + (ypt - radius2) ** 2)
        
        if distance1 <= radius1:

            if (xpt >= -radius1) & (xpt <= 0):

                if (((distance1 <= radius1) or (distance2 <= radius2)) 
                    and (distance3 > radius2)):

                    if n_yin_counter < n_yin:
                        yin.append([xpt, ypt])
                        n_yin_counter += 1

                    elif n_yang_counter < n_yang:
                        yang.append([xpt, ypt])
                        n_yang_counter += 1

                if (xpt > 0.0) & (xpt <= radius1):

                    if (((distance1 <= radius1) or (distance3 <= radius2)) 
                        and (distance2 > radius2)):

                        if n_yang_counter < n_yang:
                            yang.append([xpt, ypt])
                            n_yang_counter += 1

                    elif n_yin_counter < n_yin:
                        yin.append([xpt, ypt])
                        n_yin_counter += 1

    # translate each sample in yin and yang for the origin to the
    # center of the plot. for implementing overlap, the overlap
    # parameter multiply to one of the plot center points. So the
    # the overlap parameter interferes in translation process.
    #
    yang = np.array(yang) + np.array([params['x_mean'], params['y_mean']])
    yin = np.array(yin) + np.array([params['x_mean'], params['y_mean']]) * (1 + params['ovlp'])

    # combine the yin and yang classes and create the labels
    #
    X = np.concatenate((yin, yang), axis=0)
    y = ['Class0'] * n_yin + ['Class1'] * n_yang

    # exit gracefully
    #
    return X, y
#
# end of method